{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e4e04d7-b258-4767-b519-ba3b811ef03e",
   "metadata": {},
   "source": [
    "<center><img src='../../img/ai4eo_logos.jpg' alt='Logos AI4EO MOOC' width='80%'></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6951d76-1387-43bf-8cd8-d58efd4dff2c",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dab78c-a5ed-4bd9-8849-f0702fcc1379",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e8b2d-f02e-4011-963c-5a2c4423eab9",
   "metadata": {},
   "source": [
    "<a href=\"../00_index.ipynb\"><< Index</a><br>\n",
    "<a href=\"./\"><< Placeholder 1</a><span style=\"float:right;\"><a href=\"./\">Placeholder 2 >></a></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eedc30-df92-491b-9efe-74433217d75d",
   "metadata": {},
   "source": [
    "# 3H - Aesthetics Aware Reinforcement Learning for Image-Cropping (Functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054d1508-de8d-4f5d-b985-b88a175aa00c",
   "metadata": {},
   "source": [
    "<i>by Carlos Fortuny-Lombraña, EUMETSAT, Darmstadt, Germany</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f4c4da-c443-41f6-a2c2-468d22d7d6ea",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4ab8a-37b6-45aa-b85c-e76352fc47b2",
   "metadata": {},
   "source": [
    "Functions:\n",
    "* [command2action](#command2action)\n",
    "* [generate_bbox](#generate_bbox)\n",
    "* [crop_input](#crop_input)\n",
    "* [conv](#conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d169d-7d36-4b8f-81e2-4ff2393e1b3d",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d199e-0152-40d7-aadf-127e8c821038",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79438fa5-2585-421e-818f-7bb5cd86e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove warning messages\n",
    "import warnings # a library to manage warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Python packages\n",
    "import tensorflow.compat.v1 as tf #Importing the TensorFlow Version 1 for ML\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)  #Remove all the error messages due to TensorFlow\n",
    "tf.disable_v2_behavior() # Disable Tensorflow Version 2\n",
    "import keras # a high-level neural networks library\n",
    "import numpy as np # Python's array manipulation library \n",
    "import skimage.transform as transform # a library that cointains a collection of algorithms for image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdeb100-fc1d-4ba2-8f39-d900f0c7ce16",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3d8216-a837-495f-af5f-3ca8a06c4950",
   "metadata": {},
   "source": [
    "### <a id='command2action'></a> `command2action`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7521ae-1f06-401b-ad3c-98526e23fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def command2action(command_ids, ratios, terminals):\n",
    "    batch_size = len(command_ids)\n",
    "    for i in range(batch_size):\n",
    "        if terminals[i] == 1:\n",
    "            continue\n",
    "        if command_ids[i] == 0:\n",
    "            ratios[i, 0] += 1\n",
    "            ratios[i, 1] += 1\n",
    "            ratios[i, 2] -= 1\n",
    "            ratios[i, 3] -= 1\n",
    "        elif command_ids[i] == 1:\n",
    "            ratios[i, 2] -= 1\n",
    "            ratios[i, 3] -= 1\n",
    "        elif command_ids[i] == 2:\n",
    "            ratios[i, 0] += 1\n",
    "            ratios[i, 3] -= 1\n",
    "        elif command_ids[i] == 3:\n",
    "            ratios[i, 1] += 1\n",
    "            ratios[i, 2] -= 1\n",
    "        elif command_ids[i] == 4:\n",
    "            ratios[i, 0] += 1\n",
    "            ratios[i, 1] += 1\n",
    "        elif command_ids[i] == 5:\n",
    "            ratios[i, 0] += 1\n",
    "            ratios[i, 2] += 1\n",
    "        elif command_ids[i] == 6:\n",
    "            ratios[i, 0] -= 1\n",
    "            ratios[i, 2] -= 1\n",
    "        elif command_ids[i] == 7:\n",
    "            ratios[i, 1] -= 1\n",
    "            ratios[i, 3] -= 1\n",
    "        elif command_ids[i] == 8:\n",
    "            ratios[i, 1] += 1\n",
    "            ratios[i, 3] += 1\n",
    "        elif command_ids[i] == 9:\n",
    "            ratios[i, 1] += 1\n",
    "            ratios[i, 3] -= 1\n",
    "        elif command_ids[i] == 10:\n",
    "            ratios[i, 0] += 1\n",
    "            ratios[i, 2] -= 1\n",
    "        elif command_ids[i] == 11:\n",
    "            ratios[i, 1] -= 1\n",
    "            ratios[i, 3] += 1\n",
    "        elif command_ids[i] == 12:\n",
    "            ratios[i, 0] -= 1\n",
    "            ratios[i, 2] += 1\n",
    "        elif command_ids[i] == 13:\n",
    "            terminals[i] = 1\n",
    "        else:\n",
    "            raise NameError('undefined command type !!!')\n",
    "\n",
    "        ratios = np.maximum(ratios, 0)\n",
    "        ratios = np.minimum(ratios, 20)\n",
    "        if ratios[i, 2] - ratios[i, 0] <= 4 or ratios[i, 3] - ratios[i, 1] <= 4:\n",
    "            terminals[i] = 1\n",
    "\n",
    "    return ratios, terminals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee84bc4-7f40-40fb-b196-bdac3483b3b3",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2c018-ab84-46b3-a076-41d8ee2aa88b",
   "metadata": {},
   "source": [
    "### <a id='generate_bbox'></a> `generate_bbox`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df2f606-c8bb-48e1-b6c1-22bf53981057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bbox(input_np, ratios):\n",
    "    assert len(input_np) == len(ratios)\n",
    "\n",
    "    bbox = []\n",
    "    for im, ratio in zip(input_np, ratios):\n",
    "        height, width = im.shape[:2]\n",
    "        xmin = int(float(ratio[0]) / 20 * width)\n",
    "        ymin = int(float(ratio[1]) / 20 * height)\n",
    "        xmax = int(float(ratio[2]) / 20 * width)\n",
    "        ymax = int(float(ratio[3]) / 20 * height)\n",
    "        \n",
    "        bbox.append((xmin, ymin, xmax, ymax))\n",
    "        \n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7481c9-3f1d-4529-9d41-217cb2e126e5",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaea2f4-b69d-4783-bd40-18e560002cb4",
   "metadata": {},
   "source": [
    "### <a id='crop_input'></a> `crop_input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0ef757-6785-440c-835f-7fcbbe27c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_input(input_np, bbox):\n",
    "        assert len(input_np) == len(bbox)\n",
    "    \n",
    "        result = [transform.resize(im[ymin:ymax, xmin:xmax], (227, 227), mode='constant')\n",
    "                        for im, (xmin, ymin, xmax, ymax) in zip(input_np, bbox)]\n",
    "    \n",
    "        return np.asarray(result, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e4a26-1a1e-478f-8559-d77d33d9c621",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043205d4-df00-4d77-bdc8-8bf949543eca",
   "metadata": {},
   "source": [
    "### <a id='conv'></a> `conv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d00a583-622b-4f25-a740-1fefcca26734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input, kernel, biases, k_h, k_w, c_o, s_h, s_w,  padding=\"VALID\", group=1):\n",
    "    # Taken from https://github.com/ethereon/caffe-tensorflow\n",
    "    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "    if group==1:\n",
    "        conv = convolve(input, kernel)\n",
    "    else:\n",
    "        input_groups = tf.split(input, group, 3)\n",
    "        kernel_groups = tf.split(kernel, group, 3)\n",
    "        output_groups = [convolve(i, k) for i,k in zip(input_groups, kernel_groups)]\n",
    "        conv = tf.concat(output_groups, 3)\n",
    "    return  tf.nn.bias_add(conv, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153119b-bd81-4414-a818-a2182774cac5",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<a href=\"../00_index.ipynb\"><< Index</a><br>\n",
    "<a href=\"./\"><< Placeholder 1</a><span style=\"float:right;\"><a href=\"./\">Placeholder 2 >></a></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb9ac50-895e-4a8e-954c-2f648a11975f",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f755b7-b00f-4825-8f28-67fdf0a48abb",
   "metadata": {},
   "source": [
    "<img src='../../../img/copernicus_logo.png' alt='Copernicus logo' align='left' width='20%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c3cb4c-06c9-4bd1-9db1-9b937aabc3b1",
   "metadata": {},
   "source": [
    "Course developed for [EUMETSAT](https://www.eumetsat.int/), [ECMWF](https://www.ecmwf.int/) and [Mercator Ocean International](https://www.mercator-ocean.fr/en/) in support of the [EU’s Copernicus Programme](https://www.copernicus.eu/en) and the [WEkEO platform](https://wekeo.eu/).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
